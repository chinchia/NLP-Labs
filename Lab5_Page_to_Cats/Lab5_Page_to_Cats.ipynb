{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPES <span style='font-size:20px'>: Majority Parentheses Expression by Sister pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from nltk import word_tokenize\n",
    "from math import log, sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load page_category\n",
    "`Format example`\n",
    "```python\n",
    "page_category = {\n",
    "    'Bass (fish)' : ['Category:Fish common names'],\n",
    "    'Star (automobile)' : ['Category:Defunct motor vehicle manufacturers of the United States', 'Category:Durant Motors'],\n",
    "    ...\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Category:Fish common names']\n"
     ]
    }
   ],
   "source": [
    "with open('page-to-cats.json') as f:\n",
    "    page_category = json.load(f)\n",
    "\n",
    "print(page_category['Bass (fish)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Count the classes of categories\n",
    "For each category, count the appearance of words(possible classes) in the title of the pages under it\n",
    "- you may use **`page_to_class()`**\n",
    "\n",
    "example:\n",
    "```python\n",
    "category_class_count['Category:Fish common names']['fish'] = 16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fish']\n"
     ]
    }
   ],
   "source": [
    "# count the appearance of possible classes in the page title\n",
    "def page_to_class(page):\n",
    "    class_list = []\n",
    "    if '(' in page and 'disambiguation' not in page:\n",
    "        class_list.append(page.split('(')[1][:-1])\n",
    "    return class_list\n",
    "\n",
    "\n",
    "print(page_to_class('Bass (fish)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_class_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for page, category_list in page_category.items():\n",
    "    for page_class in page_to_class(page):\n",
    "        for category in category_list:\n",
    "            ##### YOUR CODE HERE #####\n",
    "            if category not in category_class_count.keys():\n",
    "                category_class_count[category][page_class] = 1\n",
    "            else:\n",
    "                category_class_count[category][page_class] += 1\n",
    "            \n",
    "category_class_count['Category:Fish common names']['fish']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Freshwater fish such as bream, shad, bass, and sucker are common.',\n",
       " \"American black bear, racking horse, yellow-shafted flicker, wild turkey, Atlantic tarpon, largemouth bass, southern longleaf pine, eastern tiger swallowtail, monarch butterfly, Alabama red-bellied turtle, Red Hills salamander, camellia, oak-leaf hydrangea, peach, pecan, and blackberry are Alabama's state symbols.\",\n",
       " 'Besides salmon and trout, sport-fishers in BC also catch halibut, steelhead, bass, and sturgeon.',\n",
       " 'Sport fishing, commercial fishing, and Native American fishing represent a U.S.$4 billion a year industry with salmon, whitefish, smelt, lake trout, bass and walleye being major catches.',\n",
       " 'Several ferries currently operate on the Great Lakes to carry passengers to various islands, including Isle Royale, Drummond Island, Pelee Island, Mackinac Island, Beaver Island, Bois Blanc Island (Ontario), Bois Blanc Island (Michigan), Kelleys Island, South Bass Island, North Manitou Island, South Manitou Island, Harsens Island, Manitoulin Island, and the Toronto Islands.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sentences.json') as f:\n",
    "    sentences = json.load(f)\n",
    "    \n",
    "    \n",
    "sentences['bass']['Bass (fish)'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decide class of wikipedia pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each page in **sentences.json**, sum up the count of classes of all the categories it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example:\n",
    "```python\n",
    "page_class_count['Bass (fish)'] = \n",
    "    {\n",
    "        ...,\n",
    "        'mackerel': 2,\n",
    "        'bass': 2,\n",
    "        'fish': 16,\n",
    "        'hake': 1,\n",
    "        'sea': 1,\n",
    "        ...\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>,\n",
       "            {'fisheries term': 1, 'fish': 16})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_class_count = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for page_list in sentences.values():\n",
    "    for page in page_list:\n",
    "        for category in page_category[page]:\n",
    "            for c, count in category_class_count[category].items():\n",
    "                ##### YOUR CODE HERE #####\n",
    "                page_class_count[page][c] = count\n",
    "                \n",
    "page_class_count['Bass (fish)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, for each page, choose the class with the maximum count.\n",
    "\n",
    "example:\n",
    "```python\n",
    "page_class['Bass (fish)'] = 'fish'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fish'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_class = defaultdict(dict)\n",
    "\n",
    "for page, class_counts in page_class_count.items():\n",
    "    ##### YOUR CODE HERE #####\n",
    "    max_val = 0\n",
    "    for k, v in class_counts.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    page_class[page] = max_key\n",
    "\n",
    "page_class['Bass (fish)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Combine sentences which have the same class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- construct __class_sents__ using __page_class__ & __sentences__ dictionaries\n",
    "\n",
    "`Format`\n",
    "```python\n",
    "class_sents = {\n",
    "    word: {\n",
    "        Class: {\n",
    "            [ sent_1, sent_2, ... ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "```\n",
    "`Examples`\n",
    "\n",
    "```python\n",
    "1.\n",
    "list(class_sents.keys())\n",
    "['star',\n",
    " 'mole',\n",
    " 'galley',\n",
    " 'cone',\n",
    " 'bass',\n",
    " 'bow',\n",
    " 'taste',\n",
    " 'interest',\n",
    " 'issue',\n",
    " 'duty',\n",
    " 'sentence',\n",
    " 'slug']\n",
    "\n",
    "2. \n",
    "list(class_sents['bass'].keys())\n",
    "['fish', 'music', 'sound']\n",
    "\n",
    "3.\n",
    "len(class_sents['bass']['fish']) = 668\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['star', 'mole', 'galley', 'cone', 'bass', 'bow', 'taste', 'interest', 'issue', 'duty', 'sentence', 'slug']\n",
      "['fish', 'music', 'sound']\n",
      "668\n"
     ]
    }
   ],
   "source": [
    "class_sents = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for word, v in sentences.items():\n",
    "    for page, sents in v.items():\n",
    "        ##### YOUR CODE HERE #####\n",
    "        cls = page_class[page]\n",
    "        class_sents[word][cls] = sents\n",
    "\n",
    "print(list(class_sents.keys()))\n",
    "print(list(class_sents['bass'].keys()))\n",
    "print(len(class_sents['bass']['fish']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Method - Yarowsky92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ weight_{ijk} = log(\\frac{Pr(w_i|Class_j)}{Pr(w_i|word_k)})$\n",
    "<br><br>\n",
    "where<br> \n",
    "$Pr(w_i|Class_j) = \\frac{Counts\\;of\\;w_i\\;in\\;Class_j}{Counts\\;of\\;all\\;words\\;in\\;Class_j}$<br><br>\n",
    "$Pr(w_i|word_k) = \\frac{Counts\\;of\\;w_i\\;in\\;word_k}{Counts\\;of\\;all\\;words\\;in\\;word_k}$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "`Instruction`\n",
    "\n",
    "Step 1. For each $word_k$, tokenize every sentences and count all words in $word_k$ as N<br>\n",
    "Step 2. For each $class_j$, count all words in $class_j$ as n<br>\n",
    "Step 3. For each word $w_i$, count occurances in $class_j$ and $word_k$, repectively.<br>\n",
    "Step 4. Calculate $weight_{ijk}$\n",
    "\n",
    "\n",
    "`Example`\n",
    "```python\n",
    "weight['bass']['fish']['freshwater'] = 3.0273651127101293\n",
    "max(weight['bass']['fish'].items(), key = lambda x: x[1]) = ('bream', 3.1972901141524415)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.098409592400567\n",
      "('sucker', 2.2161926280569504)\n"
     ]
    }
   ],
   "source": [
    "weight = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.0)))\n",
    "\n",
    "for word, v in class_sents.items():\n",
    "    total_words = {}\n",
    "    for wiki_class, sents in v.items():\n",
    "        total_words[wiki_class] = Counter([word.lower() for sent in sents for word in word_tokenize(sent)])\n",
    "    N = sum([sum(v.values()) for k,v in total_words.items()]) ##### Finish it #####\n",
    "    for wiki_class, sents in v.items():\n",
    "        n = sum(total_words[wiki_class].values()) ##### Finish it #####\n",
    "        for tks in total_words[wiki_class]:\n",
    "            ##### YOUR CODE HERE #####\n",
    "            prob_class = total_words[wiki_class][tks] / n\n",
    "            prob_word = sum([v[tks] for k,v in total_words.items()]) / N\n",
    "            weight[word][wiki_class][tks] = np.log(prob_class / prob_word)\n",
    "            \n",
    "print(weight['bass']['fish']['freshwater'])\n",
    "print(max(weight['bass']['fish'].items(), key = lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify sentence with max weight \n",
    "\n",
    "$ score = \\sum\\limits_{w\\in context}weight_w $\n",
    "\n",
    "`Example`\n",
    "```python\n",
    "most_similar('bass', 'Bass, catfish, and bluegill also inhabit the creek.') \n",
    "    = (\"fish\", 14.814981643783032)\n",
    "\n",
    "most_similar('issue', 'He\\'s contributed to several publications, including LA Review of Books, Purple, Issue, and Hesperios Journal.') \n",
    "    = (\"magazine\", 5.123843862532843)\n",
    "\n",
    "most_similar('sentence', 'If it finds the accused guilty, it passes sentence on the accused according to law.') \n",
    "    = (\"law\", 5.77941354006321)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, query):\n",
    "    max_class, max_value = ('', np.NINF)\n",
    "    q_tokens = word_tokenize(query)\n",
    "    ##### YOUR CODE HERE #####\n",
    "    for k,v in weight[word].items():\n",
    "        val = 0\n",
    "        for i in q_tokens:\n",
    "            val += v[i]\n",
    "        if val > max_value:\n",
    "            max_value = val\n",
    "            max_class = k\n",
    "    \n",
    "    return (max_class, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict class: fish (10.268962756435553)\n",
      "Correct class: fish\n",
      "\n",
      "Predict class: magazine (3.5515779269440215)\n",
      "Correct class: magazine\n",
      "\n",
      "Predict class: law (3.877911528970078)\n",
      "Correct class: law\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = [['bass', 'fish', 'Bass, catfish, and bluegill also inhabit the creek.'],\n",
    "             ['issue', 'magazine', 'He\\'s contributed to several publications, including LA Review of Books, Purple, Issue, and Hesperios Journal.'],\n",
    "             ['sentence', 'law', 'If it finds the accused guilty, it passes sentence on the accused according to law.']]\n",
    "\n",
    "# Pass the test to get 100 points\n",
    "for (word, wiki_class, query) in test_data:\n",
    "    print('Predict class: %s (%s)'%most_similar(word, query))\n",
    "    print('Correct class: %s\\n'%wiki_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bouns - Classification 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Method - tf-idf weights\n",
    "\n",
    "\n",
    "`term frequency`<br><br>$f_{i,j}$\n",
    "<br>\n",
    "\n",
    "`log normalization term frequency weight`<br><br>\n",
    "$ 1 + log_2 f_{i,j} $,\n",
    "<br>\n",
    "\n",
    "where $f_{i,j}$ is times term i occur in document j, <br>\n",
    "(One document is one class in there)\n",
    "<br><br>\n",
    "`inverse document frequency`<br><br>\n",
    "$ log_2( \\frac{N}{n_i}) $,\n",
    "\n",
    "where $N$ is number of documents, <br>\n",
    "and $n_i$ is times of term i occur in documents\n",
    "<br><br>\n",
    "`Examples`\n",
    "```Python\n",
    "term_doc_tf['star']['film']['role'] = 2.584962500721156\n",
    "\n",
    "term_idf['star']['role'] = 1.5849625007211563\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "1. calculate log normalization term frequency weight (term_doc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_tf = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0.0)))\n",
    "\n",
    "for word, v in class_sents.items():\n",
    "    for classes, sents in v.items():\n",
    "        tokens = Counter([tks for sent in list(map(word_tokenize, list(map(str.lower, sents)))) for tks in sent])\n",
    "        for tok in tokens:\n",
    "            if tok not in term_doc_tf[word][classes]:\n",
    "                ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "print(term_doc_tf['star']['film']['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. calculate inverse document frequency (term_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_idf = defaultdict(lambda:defaultdict(lambda: 0.0))\n",
    "\n",
    "for word, v in class_sents.items():\n",
    "    sents_tokens = [Counter([sub_s for s in list(map(word_tokenize,list(map(str.lower,sent)))) for sub_s in s]) for sent in v.values()]\n",
    "    N = len(sents_tokens)\n",
    "    for sent in sents_tokens:\n",
    "        for tok in sent:\n",
    "            ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "print(term_idf['star']['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency of the query and similarity\n",
    "\n",
    "`Term frequency`<br><br>\n",
    "$ 1 + log_2 f_{i, q} $\n",
    "\n",
    "<br>\n",
    "\n",
    "`Similarity`<br><br>\n",
    "$ sim(d_j, q) = \\frac{\\Sigma^t_{i=1} w_{i,j} \\times w_{i,q}}{ \\sqrt{\\Sigma^t_{i=1} w_{i,j}^2} \\times \\sqrt{\\Sigma^t_{i=1} w_{i,q}^2}} $\n",
    "\n",
    "where $w_{i,j} = (1 + log_2 f_{i,j}) \\times log_2( \\frac{N}{n_i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find most similar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_term_freq(query):\n",
    "    query_tf = defaultdict(lambda: 0.0)\n",
    "    tokens = word_tokenize(query.lower())\n",
    "    for tok in tokens:\n",
    "        if tok.lower() not in query_tf:\n",
    "            query_tf[tok] = (1 + log(tokens.count(tok), 2))\n",
    "    return query_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(word, query):\n",
    "    query_tf = query_term_freq(query)\n",
    "    max_class, max_value = ('', np.NINF)\n",
    "    for candid, terms in term_doc_tf[word].items():\n",
    "        ##### YOUR CODE HERE #####\n",
    "        \n",
    "\n",
    "    return (max_class, max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please pass the test\n",
    "for (word, classes, query) in test_data:\n",
    "    print('Predict class: %s (%s)'%find_most_similar(word, query))\n",
    "    print('Correct class: %s\\n'%classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
